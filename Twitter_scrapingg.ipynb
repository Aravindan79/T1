{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravindan79/T1/blob/main/Twitter_scrapingg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxavBIkEUcR9"
      },
      "source": [
        "# ***Package installation***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31jShs2hf54k",
        "outputId": "33cae39a-be5d-4557-bd7a-973710948eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: snscrape in /usr/local/lib/python3.9/dist-packages (0.6.2.20230320)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from snscrape) (4.9.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from snscrape) (2.27.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from snscrape) (4.11.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from snscrape) (3.10.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->snscrape) (2.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (1.7.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langcodes[data] in /usr/local/lib/python3.9/dist-packages (3.3.0)\n",
            "Requirement already satisfied: language-data<2.0,>=1.1 in /usr/local/lib/python3.9/dist-packages (from langcodes[data]) (1.1)\n",
            "Requirement already satisfied: marisa-trie<0.8.0,>=0.7.7 in /usr/local/lib/python3.9/dist-packages (from language-data<2.0,>=1.1->langcodes[data]) (0.7.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from marisa-trie<0.8.0,>=0.7.7->language-data<2.0,>=1.1->langcodes[data]) (67.6.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.9/dist-packages (4.1.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from pyngrok) (0.18.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from pyngrok) (6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.1/492.1 KB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0\n",
            "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 KB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.3.0 pymongo-4.3.3\n"
          ]
        }
      ],
      "source": [
        "!pip install snscrape\n",
        "!pip install langcodes[data]\n",
        "!pip install streamlit -q\n",
        "!pip install pyngrok\n",
        "!pip install pymongo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckuxHJ65M633"
      },
      "outputs": [],
      "source": [
        "from langcodes import * #for finding the language name from language codes\n",
        "import pandas as pd #for creating the dataframe\n",
        "import datetime #for finding the current timestamp\n",
        "import pytz #for finding accurate and cross platform timezone calculations\n",
        "import snscrape.modules.twitter as sntwitter #scrapping the twitter data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFb67sYwUn7G"
      },
      "source": [
        "## ***Functions for scraping and updating data***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SBh6rifjhoJ",
        "outputId": "2f5e3205-41e8-457b-cef0-b6dcb7f6f2e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing function_file2.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile function_file2.py\n",
        "#!pip install snscrape\n",
        "#!pip install langcodes[data]\n",
        "#!pip install streamlit -q\n",
        "#!pip install pyngrok\n",
        "\n",
        "\n",
        "from langcodes import * \n",
        "import pandas as pd \n",
        "import datetime \n",
        "from datetime import timedelta\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import json\n",
        "\n",
        "\n",
        "\n",
        "def scrap_datas(tag, from_date, to_date, lim):\n",
        "  query = f\"{tag} since:{from_date} until:{to_date}\"\n",
        "  limit = lim\n",
        "  d_tweets = []\n",
        "  scraper = sntwitter.TwitterSearchScraper(query)\n",
        "  for tweet in scraper.get_items():\n",
        "    if len(d_tweets) == lim:\n",
        "      break\n",
        "    else:\n",
        "      d_tweets.append([tweet.id,tweet.url,tweet.date,tweet.user.username,tweet.content,tweet.replyCount,tweet.retweetCount,tweet.lang,tweet.source, tweet.likeCount])\n",
        "\n",
        "  language_dict = {\"Unknown language [qst]\" : \"Tweets with short text\",\n",
        "                   \"Unknown language [qme]\" : \"Tweets with media link\",\n",
        "                   \"Unknown language [qam]\" : \"Tewwts with mentions only\", \n",
        "                   \"Unknown language [qct]\" : \"Tweets with cashtags\", \n",
        "                   \"Unknown language [qht]\" : \"Tweets with hashtags\",\n",
        "                   \"Unknown language\" : \"Undefined language\"}\n",
        "\n",
        "  for i in d_tweets:\n",
        "    i[7] = Language.make(language=i[7]).display_name()\n",
        "\n",
        "  for i in d_tweets:\n",
        "    if i[7] in language_dict.keys():\n",
        "      i[7] = language_dict[i[7]]\n",
        "    else:\n",
        "      i[7] = i[7]\n",
        "\n",
        "  da = pd.DataFrame(d_tweets, columns = [\"Id\", \"URL\", \"Date posted\", \"User Name\", \"Content\", \"Reply count\", \"Retweet count\", \"Language\", \"Source\" , \"Like count\"])\n",
        "  da[\"Source\"] = da[\"Source\"].apply(lambda x:x.split(\"=\")[1].strip(\"rel\"))\n",
        "  da[\"Id\"] = da[\"Id\"].astype(\"str\")\n",
        "  return da\n",
        "\n",
        "def update_data(tag, df_name):\n",
        "  df_name[\"Date posted\"] = df_name[\"Date posted\"].apply(lambda x:(str(x)).split(\"+\")[0])\n",
        "  #Creating document of the fetched data\n",
        "  data_list = []\n",
        "  for i in range(df_name.shape[0]):\n",
        "    x = pd.DataFrame.to_json(df_name.iloc[i, :])\n",
        "    data_list.append(json.loads(x))\n",
        "\n",
        "  #connecting to the server\n",
        "  import pymongo\n",
        "  client = pymongo.MongoClient(\"mongodb+srv://Aravindan:12345@cluster0.imr9pza.mongodb.net\")\n",
        "  db = client.Twitter_data\n",
        "  records = db.Twitter\n",
        "  #inserting document into the database\n",
        "  x = datetime.datetime.now()+timedelta(minutes = 330)\n",
        "  cur_tsr = str(x).split(\".\")[0]\n",
        "  htag = tag+\"_\"+cur_tsr\n",
        "  daata = {htag : data_list}\n",
        "  info = records.insert_one(daata)\n",
        "  if info != 0:\n",
        "    return \"Inserted succcessfully\"\n",
        "  elif info == 0:\n",
        "    return \"Something went wrong please try again\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVH4UwvntvGb"
      },
      "source": [
        "# ***GUI app creation***\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKEnr-bEH_3P",
        "outputId": "97b23ded-6d16-4c49-9006-9f2fc91dd04b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok==4.1.1\n",
            "  Downloading pyngrok-4.1.1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from pyngrok==4.1.1) (0.18.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from pyngrok==4.1.1) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-4.1.1-py3-none-any.whl size=15979 sha256=9a9f6376519d5a0c41da67e474b6ea5f4348bceb839da03c8dbfab8c1d3c805e\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/2d/c2/abe6bcfde6bce368c00ecd73310c11edb672c3eda09a090cfa\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "  Attempting uninstall: pyngrok\n",
            "    Found existing installation: pyngrok 5.2.1\n",
            "    Uninstalling pyngrok-5.2.1:\n",
            "      Successfully uninstalled pyngrok-5.2.1\n",
            "Successfully installed pyngrok-4.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok==4.1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N518rVZbmJw"
      },
      "source": [
        " **⬇** **Dont run Authorization cell more than once. !!! If you re-run the cell the tunnel creation is intrupted**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_UfA98EWz4j",
        "outputId": "382260aa-1bc5-449d-a743-0ceca35a1ee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken 2KpDqTZUtehyXWcqN3MmStzyALP_6d4iQSEbfH4vMnbYSFBMZ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmCFC6fvmnm4",
        "outputId": "a9c86e06-66b4-4e5b-aed4-44f8ae7484c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-30 15:43:53--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.237.133.81, 54.161.241.46, 52.202.168.65, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.237.133.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13921656 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \rngrok-stable-linux- 100%[===================>]  13.28M  79.3MB/s    in 0.2s    \n",
            "\n",
            "2023-03-30 15:43:54 (79.3 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13921656/13921656]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -qq ngrok-stable-linux-amd64.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSDJ-DRsP17e",
        "outputId": "06f1dc58-6161-4beb-fe0f-b2259b8f26eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile streamlit_app.py\n",
        "import json\n",
        "from function_file2 import  scrap_datas, update_data\n",
        "import streamlit as st\n",
        "\n",
        "\n",
        "st.markdown(\"<h1 style='text-align: left; color: white;'>Tweets Scrapping</h1>\", unsafe_allow_html=True)\n",
        "hashtag = st.text_input('Enter your hashtag for search', '#')\n",
        "f_date = st.date_input('Enter your Start Date')\n",
        "from_date = str(f_date).replace(\"/\", \"-\")\n",
        "t_date = st.date_input('Enter your End Date')\n",
        "to_date = str(t_date).replace(\"/\", \"-\")\n",
        "limit = st.number_input('Set Limit', 10)\n",
        "if st.button(\"Display Data\"):\n",
        "  df = scrap_datas(hashtag, from_date, to_date, limit)\n",
        "  st.table(df)\n",
        "if st.button(\"Download Data\"):\n",
        "  df = scrap_datas(hashtag, from_date, to_date, limit)\n",
        "  df_c = df.copy()\n",
        "  df_c[\"Id\"] = df_c[\"Id\"].astype(\"str\")\n",
        "  df_csv = df_c.to_csv()\n",
        "  st.download_button(\"Download as CSV\",data = df_csv,file_name = f\"{hashtag}.csv\",mime='text/csv')\n",
        "  st.balloons()\n",
        "  df_json = df.to_json()\n",
        "  st.download_button(\"Download as JSON\", data = df_json, file_name = f\"{hashtag}.json\", mime=\"application/json\")\n",
        "  st.balloons()\n",
        "\n",
        "if st.button(\"Upload data to the database\"):\n",
        "  df = scrap_datas(hashtag, from_date, to_date, limit)\n",
        "  message = update_data(hashtag, df)\n",
        "  st.write(message)\n",
        "  st.balloons()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EbYwPd6caEk"
      },
      "source": [
        "click on the below link to open stramlit\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4YkDLPD9m6X",
        "outputId": "a22744f9-1ef1-427b-9dcd-f3bd52fa91f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://d34b-34-86-243-128.ngrok.io\n"
          ]
        }
      ],
      "source": [
        "get_ipython().system_raw('./ngrok http 8501 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iW9rYSpnFnq",
        "outputId": "9c4ca119-bd5d-4f30-98ae-144b3938d93e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.86.243.128:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2023-03-30 17:32:35.222 Retrieving scroll page None\n",
            "2023-03-30 17:32:35.222 Retrieving guest token\n",
            "2023-03-30 17:32:35.223 Retrieving https://twitter.com/search?f=live&lang=en&q=%23+ipl+since%3A2023-03-21+until%3A2023-03-30&src=spelling_expansion_revert_click\n",
            "2023-03-30 17:32:35.413 Retrieved https://twitter.com/search?f=live&lang=en&q=%23+ipl+since%3A2023-03-21+until%3A2023-03-30&src=spelling_expansion_revert_click: 200\n",
            "2023-03-30 17:32:35.416 Retrieving https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&include_ext_has_nft_avatar=1&include_ext_is_blue_verified=1&include_ext_verified_type=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_ext_limited_action_results=false&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_ext_collab_control=true&include_ext_views=true&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&include_ext_sensitive_media_warning=true&include_ext_trusted_friends_metadata=true&send_error_codes=true&simple_quoted_tweet=true&q=%23+ipl+since%3A2023-03-21+until%3A2023-03-30&tweet_search_mode=live&count=20&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&include_ext_edit_control=true&ext=mediaStats%2ChighlightedLabel%2ChasNftAvatar%2CvoiceInfo%2Cenrichments%2CsuperFollowMetadata%2CunmentionInfo%2CeditControl%2Ccollab_control%2Cvibe\n",
            "2023-03-30 17:32:36.246 Retrieved https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&include_ext_has_nft_avatar=1&include_ext_is_blue_verified=1&include_ext_verified_type=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_ext_limited_action_results=false&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_ext_collab_control=true&include_ext_views=true&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&include_ext_sensitive_media_warning=true&include_ext_trusted_friends_metadata=true&send_error_codes=true&simple_quoted_tweet=true&q=%23+ipl+since%3A2023-03-21+until%3A2023-03-30&tweet_search_mode=live&count=20&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&include_ext_edit_control=true&ext=mediaStats%2ChighlightedLabel%2ChasNftAvatar%2CvoiceInfo%2Cenrichments%2CsuperFollowMetadata%2CunmentionInfo%2CeditControl%2Ccollab_control%2Cvibe: 200\n",
            "/content/function_file2.py:25: DeprecatedFeatureWarning: content is deprecated, use rawContent instead\n",
            "  d_tweets.append([tweet.id,tweet.url,tweet.date,tweet.user.username,tweet.content,tweet.replyCount,tweet.retweetCount,tweet.lang,tweet.source, tweet.likeCount])\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run /content/streamlit_app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLW0fwtwdOaz"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}